{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7e38de",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"figures/course.png\" width=\"800\">\n",
    "\n",
    "#                                    16720 (B) Neural Networks for Recognition - Assignment 3\n",
    "\n",
    "     Instructor: Kris Kitani                       TAs: Qichen(Lead), Paritosh, Rawal, Yan, Zen, Wen-Hsuan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181fc55a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "737919867883dfce32adfbc15798cb81",
     "grade": false,
     "grade_id": "cell-f291112cfcde74fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q5 Image Compression with Autoencoders [Extra Credit](25 points)\n",
    "\n",
    "**Note: We would recommend finishing Question 7 (pytorch) before attempting this question**\n",
    "\n",
    "**Please include all the write up answers below to theory.ipynb. For the questions need code, you need to include the screenshot of code to theory.ipynb to get points.**\n",
    "\n",
    "An autoencoder is a neural network that is trained to attempt to copy its input to its output, but it usually allows copying only approximately. This is typically achieved by restricting the number of hidden nodes inside the autoencoder; in other words, the autoencoder would be forced to learn to \\textit{represent} data with this limited number of hidden nodes. This is a useful way of learning compressed representations.\n",
    "In this section, we will continue using the NIST36 dataset you have from the previous questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d297f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0992c4abec48e0c94b6f980a26cfb540",
     "grade": false,
     "grade_id": "cell-828e60b98b663679",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q5.1 Building the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033a3c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9778b8e3b3d1cf77661823df6ebbd58c",
     "grade": false,
     "grade_id": "cell-d40ca2df0f7c8099",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q5.1.1 (10 points Code)\n",
    "\n",
    "Due to the difficulty in training auto-encoders, we have to move to the $relu(x) = max(x,0)$ activation function. It is provided for you in **q2.ipynb**. Implement a 2 hidden layer autoencoder where the layers are \n",
    "1. 1024 to 32 dimensions, followed by a ReLU\n",
    "2. 32 to 32 dimensions, followed by a ReLU\n",
    "3. 32 to 32 dimensions, followed by a ReLU\n",
    "4. 32 to 1024 dimensions, followed by a sigmoid (this normalizes the image output for us)\n",
    "\n",
    "The loss function that you're using is total squared error for the output image compared to the input image (they should be the same!).  \n",
    "\n",
    "<font color=\"red\">**Please include the screenshot of code to theory.ipynb**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c18d6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e0534a66471434628ed30f3615b2a2e",
     "grade": true,
     "grade_id": "cell-cc6ea456439be63f",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from ipynb.fs.defs.q2 import *\n",
    "from collections import Counter\n",
    "\n",
    "train_data = scipy.io.loadmat('data/nist36_train.mat')\n",
    "valid_data = scipy.io.loadmat('data/nist36_valid.mat')\n",
    "\n",
    "# we don't need labels now!\n",
    "train_x = train_data['train_data']\n",
    "valid_x = valid_data['valid_data']\n",
    "\n",
    "max_iters = 100\n",
    "# pick a batch size, initial learning rate\n",
    "batch_size = None\n",
    "learning_rate = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "hidden_size = 32\n",
    "lr_rate = 20\n",
    "\n",
    "batches = get_random_batches(train_x,np.ones((train_x.shape[0],1)),batch_size)\n",
    "batch_num = len(batches)\n",
    "\n",
    "params = Counter()\n",
    "\n",
    "# initialize layers here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12f361",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d573c588224d82e8fbec271a4d885de1",
     "grade": false,
     "grade_id": "cell-600fa8f7515e6c59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q5.1.2 (5 points Autograder)\n",
    "\n",
    "To help even more with convergence speed, we will implement [momentum](http://cs231n.github.io/neural-networks-3/#sgd). Now, instead of updating $W = W - \\alpha \\frac{\\partial J}{\\partial W}$, we will use the update rules $M_W = 0.9 M_W - \\alpha \\frac{\\partial J}{\\partial W}$ and $W = W + M_W$. To implement this, populate the parameters dictionary with zero-initialized momentum accumulators, one for each parameter. Then simply perform both update equations for every batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70028530",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e833970e695f5ee22efe576f334c91a8",
     "grade": false,
     "grade_id": "cell-66f9e19daafebb39",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def momentum_update(w: np.ndarray, m_w: np.ndarray, grad_w: np.ndarray, alpha: float, momentum: float=0.9):\n",
    "    '''\n",
    "    Momentum update\n",
    "    \n",
    "    [input]\n",
    "    * w -- parameters\n",
    "    * m_w -- the momentum of the parameters\n",
    "    * grad_x -- parameter gradients\n",
    "    * alpha -- learning rate\n",
    "    * momentum -- the momentum factor\n",
    "    \n",
    "    [output]\n",
    "    * w -- updated parameters\n",
    "    * m_w -- updated momentum of the parameters\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return w, m_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f6469",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b30313949205258b8d3dd84cbd897be",
     "grade": true,
     "grade_id": "q5_1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7099b1da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8f61aeb5a28b505c9906e99c355c079",
     "grade": false,
     "grade_id": "cell-089645328d854467",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q5.2 Training the Autoencoder (3 Points Code+WriteUp)\n",
    " \n",
    "Using the provided default settings, train the network for 100 epochs. What do you observe in the plotted training loss curve as it progresses?\n",
    "\n",
    "\n",
    "<font color=\"red\">**Please include the write up answer and the screenshot of code to theory.ipynb**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3d256",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e18ce7f4deb0e9216b5ba8bf8c024704",
     "grade": true,
     "grade_id": "cell-febb64f32656ffc2",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# should look like your previous training loops\n",
    "for itr in range(max_iters):\n",
    "    total_loss = 0\n",
    "    for xb,_ in batches:\n",
    "        \n",
    "        # training loop can be exactly the same as q2!\n",
    "        # your loss is now squared error\n",
    "        # delta is the d/dx of (x-y)^2\n",
    "        # to implement momentum\n",
    "        #   just use 'm_'+name variables\n",
    "        #   to keep a saved value over timestamps\n",
    "        #   params is a Counter(), which returns a 0 if an element is missing\n",
    "        #   so you should be able to write your loop without any special conditions\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    if itr % 2 == 0:\n",
    "        print(\"itr: {:02d} \\t loss: {:.2f}\".format(itr,total_loss))\n",
    "    if itr % lr_rate == lr_rate-1:\n",
    "        learning_rate *= 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20fc28e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9106f19d2f0217cefffac6ada3a7631",
     "grade": false,
     "grade_id": "cell-6381f226480d9af4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q5.3 Evaluating the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4100993",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c3ce51a6849007c8baad2ecc6267672",
     "grade": false,
     "grade_id": "cell-611ea4c42210a70c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q5.3.1(4 Points Code+WriteUp)\n",
    " \n",
    "Now let’s evaluate how well the autoencoder has been trained.\n",
    " Select 5 classes from the total 36 classes in your dataset and for each selected class include in your report 2 validation images and their reconstruction. What differences do you observe that exist in the reconstructed validation images, compared to the original ones?\n",
    "\n",
    "\n",
    "<font color=\"red\">**Please include the write up answer and the screenshot of code to theory.ipynb**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee87399",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4edb1850abfcc5f05ca202b8126fd7f1",
     "grade": true,
     "grade_id": "cell-42062ddbe8ee4571",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e78427",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4036155a04c3c434109d33bd170db1dc",
     "grade": false,
     "grade_id": "cell-7cc34b3e82122c75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q5.3.2 (3 Points Code+WriteUp)\n",
    " \n",
    "Let’s evaluate the reconstruction quality using Peak Signal- to-noise Ratio (PSNR). PSNR is defined as\n",
    "\\begin{align}\n",
    "\\text{PSNR} = 20 \\times \\log_{10}(\\text{MAX}_I) - 10\\times \\log_{10}(\\text{MSE})\n",
    "\\end{align}\n",
    "where $\\text{MAX}_I$ is the maximum possible pixel value of the image, and $\\text{MSE}$ (mean squared error) is computed across all pixels. You may use [skimage.measure.compare\\_psnr](http://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.compare_psnr) for convenience. Report the average PSNR you get from the autoencoder across all validation images.\n",
    "\n",
    "<font color=\"red\">**Please include the write up answer to theory.ipynb**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1baeb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efe342abe47fa951194f5eb0bf7ecb4d",
     "grade": true,
     "grade_id": "cell-9f178c21881431bf",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "# evaluate PSNR\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
